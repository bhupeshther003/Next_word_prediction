{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Predict User New Word**\n",
        "\n",
        "<img src='https://cdn.analyticsvidhya.com/wp-content/uploads/2023/07/Screenshot_from_2023-07-14_11-04-52.png' width=500>"
      ],
      "metadata": {
        "id": "UTzCAc-rrMJ5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlV4mW2uEznh"
      },
      "outputs": [],
      "source": [
        "#  this import library\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRXS67z2TCV8"
      },
      "outputs": [],
      "source": [
        "#  import my dataset\n",
        "\n",
        "with open('/content/1661-0.txt') as f:\n",
        "  data = f.readlines()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBL3ad24TOcp",
        "outputId": "d5a4f0c5-57fc-4e3d-ab77-fa545e059ba2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "head: ['\\ufeff\\n', \"Project Gutenberg's The Adventures of Sherlock Holmes, by Arthur Conan Doyle\\n\", '\\n', 'This eBook is for the use of anyone anywhere at no cost and with\\n', 'almost no restrictions whatsoever.  You may copy it, give it away or\\n']\n",
            "tail: ['\\n', '\\n', '\\n', '\\n', '\\n']\n"
          ]
        }
      ],
      "source": [
        "# check head and tail\n",
        "\n",
        "print('head:', data[:5])\n",
        "print('tail:', data[-5:])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLZ1GFBBTSbw",
        "outputId": "bc04d604-a978-4380-94b7-3694ea853090"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3176/3176 [==============================] - 153s 47ms/step - loss: 6.3289 - accuracy: 0.0707\n",
            "Epoch 2/100\n",
            "3176/3176 [==============================] - 150s 47ms/step - loss: 5.5641 - accuracy: 0.1232\n",
            "Epoch 3/100\n",
            "3176/3176 [==============================] - 151s 48ms/step - loss: 5.1689 - accuracy: 0.1495\n",
            "Epoch 4/100\n",
            "3176/3176 [==============================] - 155s 49ms/step - loss: 4.8639 - accuracy: 0.1676\n",
            "Epoch 5/100\n",
            "3176/3176 [==============================] - 155s 49ms/step - loss: 4.5955 - accuracy: 0.1835\n",
            "Epoch 6/100\n",
            "3176/3176 [==============================] - 154s 48ms/step - loss: 4.3488 - accuracy: 0.2002\n",
            "Epoch 7/100\n",
            "3176/3176 [==============================] - 154s 48ms/step - loss: 4.1157 - accuracy: 0.2202\n",
            "Epoch 8/100\n",
            "3176/3176 [==============================] - 152s 48ms/step - loss: 3.8951 - accuracy: 0.2409\n",
            "Epoch 9/100\n",
            "3176/3176 [==============================] - 150s 47ms/step - loss: 3.6840 - accuracy: 0.2660\n",
            "Epoch 10/100\n",
            "3176/3176 [==============================] - 152s 48ms/step - loss: 3.4871 - accuracy: 0.2914\n",
            "Epoch 11/100\n",
            "3176/3176 [==============================] - 154s 48ms/step - loss: 3.3047 - accuracy: 0.3186\n",
            "Epoch 12/100\n",
            "3176/3176 [==============================] - 152s 48ms/step - loss: 3.1325 - accuracy: 0.3477\n",
            "Epoch 13/100\n",
            "3176/3176 [==============================] - 151s 48ms/step - loss: 2.9741 - accuracy: 0.3717\n",
            "Epoch 14/100\n",
            "3176/3176 [==============================] - 153s 48ms/step - loss: 2.8281 - accuracy: 0.3992\n",
            "Epoch 15/100\n",
            "3176/3176 [==============================] - 150s 47ms/step - loss: 2.6927 - accuracy: 0.4216\n",
            "Epoch 16/100\n",
            "3176/3176 [==============================] - 150s 47ms/step - loss: 2.5664 - accuracy: 0.4469\n",
            "Epoch 17/100\n",
            "3176/3176 [==============================] - 152s 48ms/step - loss: 2.4516 - accuracy: 0.4682\n",
            "Epoch 18/100\n",
            "3176/3176 [==============================] - 152s 48ms/step - loss: 2.3435 - accuracy: 0.4890\n",
            "Epoch 19/100\n",
            "3176/3176 [==============================] - 152s 48ms/step - loss: 2.2445 - accuracy: 0.5089\n",
            "Epoch 20/100\n",
            "3176/3176 [==============================] - 151s 48ms/step - loss: 2.1510 - accuracy: 0.5270\n",
            "Epoch 21/100\n",
            "3176/3176 [==============================] - 152s 48ms/step - loss: 2.0674 - accuracy: 0.5440\n",
            "Epoch 22/100\n",
            "3176/3176 [==============================] - 152s 48ms/step - loss: 1.9865 - accuracy: 0.5608\n",
            "Epoch 23/100\n",
            "3176/3176 [==============================] - 151s 48ms/step - loss: 1.9124 - accuracy: 0.5754\n",
            "Epoch 24/100\n",
            "3176/3176 [==============================] - 153s 48ms/step - loss: 1.8440 - accuracy: 0.5902\n",
            "Epoch 25/100\n",
            "3176/3176 [==============================] - 152s 48ms/step - loss: 1.7803 - accuracy: 0.6040\n",
            "Epoch 26/100\n",
            "3176/3176 [==============================] - 152s 48ms/step - loss: 1.7209 - accuracy: 0.6164\n",
            "Epoch 27/100\n",
            "3176/3176 [==============================] - 152s 48ms/step - loss: 1.6625 - accuracy: 0.6275\n",
            "Epoch 28/100\n",
            "3176/3176 [==============================] - 154s 49ms/step - loss: 1.6129 - accuracy: 0.6376\n",
            "Epoch 29/100\n",
            "3176/3176 [==============================] - 154s 48ms/step - loss: 1.5612 - accuracy: 0.6496\n",
            "Epoch 30/100\n",
            "3176/3176 [==============================] - 156s 49ms/step - loss: 1.5174 - accuracy: 0.6570\n",
            "Epoch 31/100\n",
            "3176/3176 [==============================] - 171s 54ms/step - loss: 1.4715 - accuracy: 0.6685\n",
            "Epoch 32/100\n",
            "3176/3176 [==============================] - 181s 57ms/step - loss: 1.4336 - accuracy: 0.6751\n",
            "Epoch 33/100\n",
            "3176/3176 [==============================] - 153s 48ms/step - loss: 1.3942 - accuracy: 0.6845\n",
            "Epoch 34/100\n",
            "3176/3176 [==============================] - 152s 48ms/step - loss: 1.3575 - accuracy: 0.6916\n",
            "Epoch 35/100\n",
            "3176/3176 [==============================] - 153s 48ms/step - loss: 1.3221 - accuracy: 0.7005\n",
            "Epoch 36/100\n",
            "3176/3176 [==============================] - 153s 48ms/step - loss: 1.2915 - accuracy: 0.7066\n",
            "Epoch 37/100\n",
            "3176/3176 [==============================] - 152s 48ms/step - loss: 1.2588 - accuracy: 0.7128\n",
            "Epoch 38/100\n",
            "3176/3176 [==============================] - 151s 48ms/step - loss: 1.2299 - accuracy: 0.7196\n",
            "Epoch 39/100\n",
            "3176/3176 [==============================] - 153s 48ms/step - loss: 1.2031 - accuracy: 0.7246\n",
            "Epoch 40/100\n",
            "3176/3176 [==============================] - 153s 48ms/step - loss: 1.1790 - accuracy: 0.7309\n",
            "Epoch 41/100\n",
            "3176/3176 [==============================] - 153s 48ms/step - loss: 1.1520 - accuracy: 0.7353\n",
            "Epoch 42/100\n",
            "3176/3176 [==============================] - 152s 48ms/step - loss: 1.1264 - accuracy: 0.7405\n",
            "Epoch 43/100\n",
            "3176/3176 [==============================] - 154s 49ms/step - loss: 1.1081 - accuracy: 0.7452\n",
            "Epoch 44/100\n",
            "3176/3176 [==============================] - 152s 48ms/step - loss: 1.0842 - accuracy: 0.7503\n",
            "Epoch 45/100\n",
            "3176/3176 [==============================] - 152s 48ms/step - loss: 1.0656 - accuracy: 0.7549\n",
            "Epoch 46/100\n",
            "3176/3176 [==============================] - 152s 48ms/step - loss: 1.0466 - accuracy: 0.7585\n",
            "Epoch 47/100\n",
            "3176/3176 [==============================] - 152s 48ms/step - loss: 1.0293 - accuracy: 0.7603\n",
            "Epoch 48/100\n",
            "3176/3176 [==============================] - 157s 49ms/step - loss: 1.0131 - accuracy: 0.7652\n",
            "Epoch 49/100\n",
            "3176/3176 [==============================] - 161s 51ms/step - loss: 0.9955 - accuracy: 0.7682\n",
            "Epoch 50/100\n",
            "3176/3176 [==============================] - 162s 51ms/step - loss: 0.9790 - accuracy: 0.7722\n",
            "Epoch 51/100\n",
            "3176/3176 [==============================] - 167s 53ms/step - loss: 0.9658 - accuracy: 0.7747\n",
            "Epoch 52/100\n",
            "3176/3176 [==============================] - 161s 51ms/step - loss: 0.9500 - accuracy: 0.7783\n",
            "Epoch 53/100\n",
            "3176/3176 [==============================] - 152s 48ms/step - loss: 0.9366 - accuracy: 0.7810\n",
            "Epoch 54/100\n",
            "3176/3176 [==============================] - 152s 48ms/step - loss: 0.9228 - accuracy: 0.7844\n",
            "Epoch 55/100\n",
            "3176/3176 [==============================] - 152s 48ms/step - loss: 0.9095 - accuracy: 0.7886\n",
            "Epoch 56/100\n",
            "3176/3176 [==============================] - 150s 47ms/step - loss: 0.8984 - accuracy: 0.7893\n",
            "Epoch 57/100\n",
            "3176/3176 [==============================] - 152s 48ms/step - loss: 0.8899 - accuracy: 0.7897\n",
            "Epoch 58/100\n",
            "3176/3176 [==============================] - 153s 48ms/step - loss: 0.8749 - accuracy: 0.7943\n",
            "Epoch 59/100\n",
            "3176/3176 [==============================] - 152s 48ms/step - loss: 0.8663 - accuracy: 0.7957\n",
            "Epoch 60/100\n",
            "3176/3176 [==============================] - 153s 48ms/step - loss: 0.8543 - accuracy: 0.7980\n",
            "Epoch 61/100\n",
            "3176/3176 [==============================] - 153s 48ms/step - loss: 0.8440 - accuracy: 0.7998\n",
            "Epoch 62/100\n",
            "3176/3176 [==============================] - 151s 48ms/step - loss: 0.8363 - accuracy: 0.8021\n",
            "Epoch 63/100\n",
            "3176/3176 [==============================] - 152s 48ms/step - loss: 0.8272 - accuracy: 0.8039\n",
            "Epoch 64/100\n",
            "3176/3176 [==============================] - 153s 48ms/step - loss: 0.8178 - accuracy: 0.8051\n",
            "Epoch 65/100\n",
            "3176/3176 [==============================] - 152s 48ms/step - loss: 0.8085 - accuracy: 0.8079\n",
            "Epoch 66/100\n",
            "3176/3176 [==============================] - 152s 48ms/step - loss: 0.8032 - accuracy: 0.8082\n",
            "Epoch 67/100\n",
            "3176/3176 [==============================] - 152s 48ms/step - loss: 0.7935 - accuracy: 0.8110\n",
            "Epoch 68/100\n",
            "3176/3176 [==============================] - 155s 49ms/step - loss: 0.7866 - accuracy: 0.8117\n",
            "Epoch 69/100\n",
            "3176/3176 [==============================] - 153s 48ms/step - loss: 0.7805 - accuracy: 0.8130\n",
            "Epoch 70/100\n",
            "3176/3176 [==============================] - 153s 48ms/step - loss: 0.7748 - accuracy: 0.8137\n",
            "Epoch 71/100\n",
            "3176/3176 [==============================] - 153s 48ms/step - loss: 0.7664 - accuracy: 0.8159\n",
            "Epoch 72/100\n",
            "3176/3176 [==============================] - 153s 48ms/step - loss: 0.7582 - accuracy: 0.8174\n",
            "Epoch 73/100\n",
            "3176/3176 [==============================] - 152s 48ms/step - loss: 0.7546 - accuracy: 0.8185\n",
            "Epoch 74/100\n",
            "3176/3176 [==============================] - 153s 48ms/step - loss: 0.7459 - accuracy: 0.8198\n",
            "Epoch 75/100\n",
            "3176/3176 [==============================] - 155s 49ms/step - loss: 0.7453 - accuracy: 0.8197\n",
            "Epoch 76/100\n",
            "3176/3176 [==============================] - 155s 49ms/step - loss: 0.7350 - accuracy: 0.8216\n",
            "Epoch 77/100\n",
            "3176/3176 [==============================] - 154s 48ms/step - loss: 0.7346 - accuracy: 0.8215\n",
            "Epoch 78/100\n",
            "3176/3176 [==============================] - 155s 49ms/step - loss: 0.7261 - accuracy: 0.8238\n",
            "Epoch 79/100\n",
            "3176/3176 [==============================] - 153s 48ms/step - loss: 0.7227 - accuracy: 0.8240\n",
            "Epoch 80/100\n",
            "3176/3176 [==============================] - 152s 48ms/step - loss: 0.7182 - accuracy: 0.8253\n",
            "Epoch 81/100\n",
            "3176/3176 [==============================] - 153s 48ms/step - loss: 0.7104 - accuracy: 0.8263\n",
            "Epoch 82/100\n",
            "3176/3176 [==============================] - 154s 49ms/step - loss: 0.7084 - accuracy: 0.8283\n",
            "Epoch 83/100\n",
            "3176/3176 [==============================] - 152s 48ms/step - loss: 0.7053 - accuracy: 0.8273\n",
            "Epoch 84/100\n",
            "3176/3176 [==============================] - 155s 49ms/step - loss: 0.6980 - accuracy: 0.8300\n",
            "Epoch 85/100\n",
            "3176/3176 [==============================] - 157s 50ms/step - loss: 0.6961 - accuracy: 0.8290\n",
            "Epoch 86/100\n",
            "3176/3176 [==============================] - 153s 48ms/step - loss: 0.6899 - accuracy: 0.8298\n",
            "Epoch 87/100\n",
            "3176/3176 [==============================] - 154s 48ms/step - loss: 0.6904 - accuracy: 0.8301\n",
            "Epoch 88/100\n",
            "3176/3176 [==============================] - 154s 48ms/step - loss: 0.6864 - accuracy: 0.8306\n",
            "Epoch 89/100\n",
            "3176/3176 [==============================] - 154s 48ms/step - loss: 0.6811 - accuracy: 0.8313\n",
            "Epoch 90/100\n",
            "3176/3176 [==============================] - 153s 48ms/step - loss: 0.6801 - accuracy: 0.8320\n",
            "Epoch 91/100\n",
            "3176/3176 [==============================] - 152s 48ms/step - loss: 0.6740 - accuracy: 0.8331\n",
            "Epoch 92/100\n",
            "3176/3176 [==============================] - 153s 48ms/step - loss: 0.6743 - accuracy: 0.8324\n",
            "Epoch 93/100\n",
            "3176/3176 [==============================] - 154s 49ms/step - loss: 0.6676 - accuracy: 0.8339\n",
            "Epoch 94/100\n",
            "3176/3176 [==============================] - 154s 49ms/step - loss: 0.6639 - accuracy: 0.8347\n",
            "Epoch 95/100\n",
            "3176/3176 [==============================] - 154s 48ms/step - loss: 0.6618 - accuracy: 0.8366\n",
            "Epoch 96/100\n",
            "3176/3176 [==============================] - 154s 48ms/step - loss: 0.6628 - accuracy: 0.8345\n",
            "Epoch 97/100\n",
            "3176/3176 [==============================] - 155s 49ms/step - loss: 0.6548 - accuracy: 0.8375\n",
            "Epoch 98/100\n",
            "3176/3176 [==============================] - 155s 49ms/step - loss: 0.6576 - accuracy: 0.8357\n",
            "Epoch 99/100\n",
            "3176/3176 [==============================] - 156s 49ms/step - loss: 0.6474 - accuracy: 0.8381\n",
            "Epoch 100/100\n",
            "3176/3176 [==============================] - 157s 49ms/step - loss: 0.6526 - accuracy: 0.8366\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b83f66d0e20>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(data)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Create input sequences\n",
        "input_sequences = []\n",
        "for line in data:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences\n",
        "max_sequence_length = max([len(seq) for seq in input_sequences])\n",
        "input_sequences = tf.keras.preprocessing.sequence.pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')\n",
        "\n",
        "# Create predictors and labels\n",
        "X, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=total_words)\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length=max_sequence_length-1))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=100, verbose=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# prediction"
      ],
      "metadata": {
        "id": "ZygRYhGerEzB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ibMPPe_BaOA",
        "outputId": "d481168b-bbde-4a26-e91b-347e96d51d58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your sentence:  i am \n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Predicted next word: far\n"
          ]
        }
      ],
      "source": [
        "# de  for predict new sentence   of user\n",
        "\n",
        "def predict_next_word(model, tokenizer, text):\n",
        "  \"\"\"\n",
        "  This function predicts the next word in a given sentence.\n",
        "\n",
        "  Args:\n",
        "    model: The trained model.\n",
        "    tokenizer: The tokenizer used to convert text to sequences.\n",
        "    text: The sentence for which the next word is to be predicted.\n",
        "\n",
        "  Returns:\n",
        "    The predicted next word.\n",
        "  \"\"\"\n",
        "\n",
        "  sequence = tokenizer.texts_to_sequences([text])\n",
        "  sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=max_sequence_length-1, padding='pre')\n",
        "  preds = np.argmax(model.predict(sequence))\n",
        "  predicted_word = \"\"\n",
        "\n",
        "  for key, value in tokenizer.word_index.items():\n",
        "      if value == preds:\n",
        "          predicted_word = key\n",
        "          break\n",
        "\n",
        "  return predicted_word\n",
        "\n",
        "# Get user input sentence\n",
        "input_sentence = input(\"Enter your sentence: \")\n",
        "\n",
        "# Predict the next word\n",
        "next_word = predict_next_word(model, tokenizer, input_sentence)\n",
        "\n",
        "# Print the predicted next word\n",
        "print(\"Predicted next word:\", next_word)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try to predict new word of user"
      ],
      "metadata": {
        "id": "FKUUUxCbpcyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predict new words list  of user\n",
        "\n",
        "def predict_new_words(seed_text, model, tokenizer, max_sequence_length, num_words):\n",
        "    \"\"\"\n",
        "    Predicts a list of new words based on a seed text.\n",
        "\n",
        "    Args:\n",
        "        seed_text: The seed text to start the prediction.\n",
        "        model: The trained LSTM model.\n",
        "        tokenizer: The tokenizer used to convert text to sequences.\n",
        "        max_sequence_length: The maximum length of the input sequences.\n",
        "        num_words: The number of new words to predict.\n",
        "\n",
        "    Returns:\n",
        "        A list of predicted words.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize an empty list to store the predicted words.\n",
        "    predicted_words = []\n",
        "\n",
        "    # Start with the seed text.\n",
        "    current_text = seed_text\n",
        "\n",
        "    # Loop for the specified number of words.\n",
        "\n",
        "\n",
        "\n",
        "    for _ in range(num_words):\n",
        "\n",
        "        # Tokenize the current text.\n",
        "        token_list = tokenizer.texts_to_sequences([current_text])[0]\n",
        "\n",
        "        # Pad the sequence.\n",
        "        token_list = tf.keras.preprocessing.sequence.pad_sequences([token_list], maxlen=max_sequence_length-1, padding='pre')\n",
        "\n",
        "        # Predict the next word probabilities.\n",
        "        predicted_probs = model.predict(token_list, verbose=0)[0]\n",
        "\n",
        "        # Get the index of the word with maximum probability.\n",
        "        predicted_index = np.argmax(predicted_probs)\n",
        "\n",
        "        # Map the index to the corresponding word.\n",
        "        predicted_word = tokenizer.index_word.get(predicted_index, \"\")\n",
        "\n",
        "        # Add the predicted word to the list.\n",
        "        predicted_words.append(predicted_word)\n",
        "\n",
        "        # Update the current text with the predicted word.\n",
        "        current_text += \" \" + predicted_word\n",
        "\n",
        "    # Return the list of predicted words.\n",
        "    return predicted_words\n",
        "\n",
        "\n",
        "# Example usage\n",
        "seed_text = \"i am \"\n",
        "predicted_words = predict_new_words(seed_text, model, tokenizer, max_sequence_length, 5)\n",
        "print(f\"Predicted words: {predicted_words}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3X5rYDqo3m1",
        "outputId": "eccabc16-fd6a-4f93-c2b9-0bc95015b148"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted words: ['far', 'from', 'to', 'remember', 'that']\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}